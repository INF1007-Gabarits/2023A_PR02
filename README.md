# Projet 02: Librairies scientifiques et graphiques et POO

- [Projet 02: Librairies scientifiques et graphiques et POO](#projet-02-librairies-scientifiques-et-graphiques-et-poo)
  - [Directives particuli√®res](#directives-particuli√®res)
  - [Introduction](#introduction)
  - [Objectifs](#objectifs)
  - [Partie 1: Analyse de Pok√©dex](#partie-1-analyse-de-pok√©dex)
    - [Pr√©paration du dataset üßπ](#pr√©paration-du-dataset-)
      - [1.0 Chargement des donn√©es](#10-chargement-des-donn√©es)
      - [1.1 Suppression des colonnes non pertinentes](#11-suppression-des-colonnes-non-pertinentes)
      - [1.2 Renommage des colonnes restantes](#12-renommage-des-colonnes-restantes)
      - [1.3. Nettoyage des donn√©es](#13-nettoyage-des-donn√©es)
      - [1.4 Correction des types de donn√©es](#14-correction-des-types-de-donn√©es)
    - [Visualisation de donn√©es üìà](#visualisation-de-donn√©es-)
      - [Quelques m√©thodes utiles pour les prochaines √©tapes](#quelques-m√©thodes-utiles-pour-les-prochaines-√©tapes)
      - [1.5 Le Spectre des Types](#15-le-spectre-des-types)
      - [1.6 La Course aux L√©gendes](#16-la-course-aux-l√©gendes)
      - [1.7 L'Ascension G√©n√©rationnelle](#17-lascension-g√©n√©rationnelle)
      - [1.8 Le Radar des √âl√©ments](#18-le-radar-des-√©l√©ments)
    - [Filtrage, tri et agr√©gation](#filtrage-tri-et-agr√©gation)
      - [1.9 Le Panth√©on des Sp√©cialistes](#19-le-panth√©on-des-sp√©cialistes)
      - [1.10 Les Liens Invisibles](#110-les-liens-invisibles)
    - [Mod√©lisation et pr√©vision](#mod√©lisation-et-pr√©vision)
      - [1.11 L'Oracle des L√©gendes](#111-loracle-des-l√©gendes)
        - [1.11.1 split\_data(df)](#1111-split_datadf)
        - [1.11.2 normalize\_data(x\_train, x\_test)](#1112-normalize_datax_train-x_test)
        - [1.11.3 train\_model(x\_train, y\_train)](#1113-train_modelx_train-y_train)
        - [1.11.4 evaluate\_model(model, x\_test, y\_test)](#1114-evaluate_modelmodel-x_test-y_test)
        - [1.11.5 predict\_legendary(df)](#1115-predict_legendarydf)
  - [Partie 2: L'Ar√®ne des Pok√©mons](#partie-2-lar√®ne-des-pok√©mons)
  - [Annexe: Guide et normes de codage](#annexe-guide-et-normes-de-codage)

<!-- :alarm_clock: [Date de remise le Dimanche 22 novembre 23h59](https://www.timeanddate.com/countdown/generic?iso=20201122T235959&p0=165&msg=Remise+TP5&font=cursive) -->

## Directives particuli√®res
* Le fichier requirements.txt contient les librairies √† installer pour faire le laboratoire;
* Il est sugg√©r√© de respecter le [guide de codage](https://github.com/INF1007-Gabarits/Guide-codage-python) et les normes pep8;
* Dans chaque programme, vous pouvez ajouter d‚Äôautres fonctions √† celles d√©crites dans l‚Äô√©nonc√© pour am√©liorer la lisibilit√©.

## Introduction
<p align="justify"> Bienvenue dans ce projet sur le monde fascinant des Pok√©mon ! Ce travail pratique se compose de deux grandes parties. Dans la premi√®re partie, nous plongerons dans une analyse d√©taill√©e de Pok√©dex en utilisant des techniques de visualisation de donn√©es, de filtrage et d'agr√©gation avec un dataset approuv√© par le Professeur Chen. Dans la seconde partie, nous allons cr√©er notre propre bataille de Pok√©mon en utilisant plusieurs concepts de la programmation orient√©e objet. Alors, √™tes-vous pr√™ts √† devenir le meilleur dresseur ? </p>

![Pythonmon](/assets/pythonmon.webp)

<p align="left"> <i>Cr√©dits: <a href="https://openai.com/blog/dall-e/">DALLE 3</a></i></p>

## Objectifs
- Se familiariser avec des techniques de visualisation de donn√©es
- Appliquer des m√©thodes de filtrage, de tri et d'agr√©gation sur des ensembles de donn√©es
- Comprendre et appliquer les concepts de la programmation orient√©e objet

## Partie 1: Analyse de Pok√©dex
Dans cette premi√®re √©tape de notre aventure, nous allons explorer les donn√©es disponibles dans un Pok√©dex. Un Pok√©dex, pour ceux qui ne sont pas familiers avec le terme, est un appareil √©lectronique de poche que les dresseurs de Pok√©mon portent avec eux pour garder des informations sur toutes les diff√©rentes esp√®ces de Pok√©mon. Pour cette analyse, nous utiliserons un dataset publiquement disponible sur [Kaggle](https://www.kaggle.com/datasets/rounakbanik/pokemon). Ce dataset a √©t√© l√©g√®rement modifi√© pour les besoins de ce projet. Il contient divers attributs sur chaque Pok√©mon, tels que leur type, leur g√©n√©ration, et bien s√ªr, leurs statistiques de combat. Nous allons employer diff√©rentes techniques de visualisation et d'analyse de donn√©es pour obtenir des insights int√©ressants sur ces cr√©atures fascinantes.

### Pr√©paration du dataset üßπ

#### 1.0 Chargement des donn√©es
Pour d√©marrer ce projet, la premi√®re √©tape consiste √† charger le dataset dans ce que nous appellerons notre "Pok√©dex". Vous utiliserez la librairie Pandas pour lire le fichier CSV qui contient toutes les donn√©es des Pok√©mon. Votre t√¢che est de compl√©ter la fonction create_pokedex() qui doit retourner un DataFrame Pandas contenant toutes les donn√©es. Apr√®s avoir cr√©√© votre Pok√©dex, jetez un premier coup d'≈ìil aux donn√©es en affichant les 5 premi√®res lignes du DataFrame.

#### 1.1 Suppression des colonnes non pertinentes
Apr√®s avoir charg√© votre dataset dans le Pok√©dex, la prochaine √©tape est de filtrer les colonnes qui nous int√©ressent vraiment. Pour cela, vous allez compl√©ter la fonction filter_columns() pour ne garder que les colonnes suivantes: **name**, **type1**, **type2**, **attack**, **defense**, **sp_attack**, **sp_defense**, **hp**, **speed**, **generation** et **is_legendary**. 

![Q1.1](/assets/Q1.1.png)

#### 1.2 Renommage des colonnes restantes

Une fois que vous avez les colonnes n√©cessaires, il serait agr√©able de renommer ces colonnes pour qu'elles soient plus lisibles. Le nouveau dataframe devrait avoir les colonnes suivantes: **Name**, **Primary Type**, **Secondary Type**, **Attack**, **Defense**, **Special** **Attack**, **Special** **Defense**, **HP**, **Speed**, **Generation** et **Legendary**.

![Q1.2](/assets/Q1.2.png)


#### 1.3. Nettoyage des donn√©es
Apr√®s avoir supprim√© et renomm√© les colonnes, le prochain pas est de nettoyer les donn√©es pour √©liminer toute irr√©gularit√© qui pourrait affecter nos analyses. Plus sp√©cifiquement, votre t√¢che consiste √† faire les choses suivantes :

- Supprimer les lignes en double
- Supprimez toutes les lignes avec des valeurs NA dans les colonnes, √† l'exception de la colonne "**Secondary Type**" o√π les valeurs NA sont acceptables (il est possible qu'un Pok√©mon n'ait qu'un seul type).
- Apr√®s des suppressions de lignes, les index de votre DataFrame peuvent √™tre en d√©sordre. R√©initialisez-les pour avoir une s√©quence ordonn√©e.

![Q1.3](/assets/Q1.3.png)

#### 1.4 Correction des types de donn√©es
Maintenant que votre ensemble de donn√©es est propre, il est temps de s'assurer que chaque colonne a le bon type de donn√©es. Pour ce faire, votre mission est de convertir les colonnes suivantes en type de donn√©es int :

- Generation
- HP
- Speed

![Q1.4](/assets/Q1.4.png)

### Visualisation de donn√©es üìà

#### Quelques m√©thodes utiles pour les prochaines √©tapes

Les DataFrame et Series Pandas ont plusieurs m√©thodes utiles pour effectuer des calculs statistiques et des op√©rations de filtrage. Voici quelques-unes des m√©thodes que vous pourriez trouver utiles pour les prochaines √©tapes:
- [mean](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html): Calcule la moyenne des valeurs d'une colonne
- [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html): Regroupe les lignes d'un DataFrame selon les valeurs d'une colonne
- [sort_values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html): Trie les lignes d'un DataFrame selon les valeurs d'une colonne
- [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html): Compte le nombre d'occurrences de chaque valeur dans une colonne
- [unique](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html): Retourne les valeurs uniques d'une colonne

#### 1.5 Le Spectre des Types

Une fois votre DataFrame impeccablement nettoy√© et typ√©, vous √™tes pr√™t √† passer √† quelque chose d'un peu plus visuel : un graphique √† secteurs (plus commun√©ment appel√© "pie chart" en anglais ü•ß) ! Vous allez utiliser la librairie Plotly pour cr√©er ce graphique. Il repr√©sentera la distribution des types primaires parmi tous les Pok√©mon de votre ensemble de donn√©es. Il nous donnera une id√©e claire de la diversit√© des types primaires dans l'univers Pok√©mon. Utilisez la fonction [px.pie](https://plotly.com/python/pie-charts/).

![Q1.5](/assets/Q1.5.png)

Quelques conseils:
- Ajustez les dimensions de graphique √† 800x600 pour une meilleure visualisation.

#### 1.6 La Course aux L√©gendes
Vous √™tes maintenant pr√™ts √† vous plonger dans le monde fascinant des Pok√©mon L√©gendaires. Pour cela, vous allez cr√©er un histogramme en utilisant la biblioth√®que Seaborn. Cet histogramme va r√©v√©ler le nombre de Pok√©mon L√©gendaires en fonction de leur g√©n√©ration. Utilisez la fonction [sns.barplot](https://seaborn.pydata.org/generated/seaborn.barplot.html).

![Q1.6](/assets/Q1.6.png)

#### 1.7 L'Ascension G√©n√©rationnelle
Le prochain d√©fi vous m√®nera √† une comparaison multi-dimensionnelle des statistiques moyennes des Pok√©mon √† travers les diff√©rentes g√©n√©rations. Vous utiliserez Plotly pour cr√©er un graphique en lignes superpos√©es, une pour chaque statistique (**Attack**, **Defense**, **HP**, **Special** **Attack**, **Special** **Defense** et **Speed**). Chaque ligne repr√©sentera la moyenne de la statistique pour chaque g√©n√©ration. Utilisez une instance de la classe [go.Figure](https://plotly.com/python/creating-and-updating-figures/) pour cr√©er votre graphique o√π vous ajouterez chacune des lignes. Cette visualisation vous aidera √† comprendre comment les statistiques moyennes des Pok√©mon ont √©volu√© au fil des g√©n√©rations.

![Q1.7](/assets/Q1.7.png)

Quelques conseils:
<!-- parler de scatter -->
- Chaque ligne du graphique peut √™tre repr√©sent√©e par un [scatter plot](https://plotly.com/python-api-reference/generated/plotly.graph_objects.Scatter.html).
- L'attribut **mode** de la classe Scatter peut √™tre utilis√© pour d√©finir le type de ligne (lignes, lignes + marqueurs, marqueurs).

#### 1.8 Le Radar des √âl√©ments

Vous √™tes sur le point d'entrer dans la bataille des √©l√©ments, o√π chaque type de Pok√©mon d√©voile ses forces et ses faiblesses en mati√®re d'Attaque, de D√©fense et de HP. Vous utiliserez Plotly pour cr√©er une s√©rie de graphiques radars qui captureront ces aspects cl√©s. Chaque graphique radar repr√©sentera la performance de tous les types de Pok√©mon pour une statistique donn√©e. Vous devez aligner horizontalement les trois graphiques radars pour faciliter la comparaison entre les types de Pok√©mon. La fonction [make_subplots](https://plotly.com/python/subplots/) peut √™tre utilis√©e pour cr√©er des sous-graphiques. Utilisez la fonction [go.Scatterpolar](https://plotly.com/python/polar-chart/) pour cr√©er les diff√©rents graphiques radars et les ajouter √† votre figure. Cette visualisation vous aidera √† comprendre les forces et les faiblesses de chaque type de Pok√©mon.

![Q1.8](/assets/Q1.8.png)

Quelques conseils:

- Redimensionnez votre figure √† 1400x600 pour une meilleure visualisation.

### Filtrage, tri et agr√©gation 

#### 1.9 Le Panth√©on des Sp√©cialistes

Dans ce segment, nous allons couronner l'√©lite des Pok√©mon en fonction de leurs statistiques cl√©s : Attaque, D√©fense, HP et Vitesse. Utilisez Pandas pour filtrer les 5 meilleurs Pok√©mon pour chaque statistique. Ce seront les Pok√©mon que vous voudrez avoir dans votre √©quipe si vous cherchez √† maximiser une statistique particuli√®re ! 

![Q1.9](/assets/Q1.9.png)

Quelques conseils:

- La m√©thode [nlargest](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nlargest.html) vous sera grandement utile pour cette t√¢che.
- Pour une meilleure pr√©sentation, utilisez la fonction [display(...)](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html) pour afficher les DataFrames au lieu de `print()`.

#### 1.10 Les Liens Invisibles

Dans cette section, nous allons plonger dans les relations intrins√®ques entre les diff√©rentes statistiques des Pok√©mon. Une matrice de corr√©lation vous permettra de mesurer √† quel point les statistiques sont interd√©pendantes. Cela donne une id√©e de la relation entre, par exemple, la vitesse et l'attaque d'un Pok√©mon : sont-ils g√©n√©ralement proportionnels ou ind√©pendants?

Utilisez la biblioth√®que Seaborn pour g√©n√©rer la matrice de corr√©lation des statistiques suivantes: **Attack**, **Defense**, **HP**, **Special** **Attack**, **Special** **Defense**, **HP** et **Speed**. Utilisez la fonction [sns.heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) pour cr√©er la matrice de corr√©lation.

![Q1.10](/assets/Q1.10.png)

Quelques conseils:

- Utilisez la palette de couleurs `crest` pour avoir le m√™me rendu que l'image ci-dessus.

### Mod√©lisation et pr√©vision 

#### 1.11 L'Oracle des L√©gendes

Dans cette section, vous allez d√©ployer vos comp√©tences en machine learning pour r√©soudre une question √©ternelle : peut-on pr√©dire si un Pok√©mon est l√©gendaire en fonction de ses statistiques ? Vous utiliserez le classificateur [k-NN (k-Nearest Neighbors)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) de la librairie Scikit-Learn pour cette mission. Le processus est d√©compos√© en plusieurs √©tapes cl√©s.

##### 1.11.1 split_data(df)

La premi√®re √©tape dans tout pipeline d'apprentissage automatique est la division du jeu de donn√©es en ensembles d'entra√Ænement et de test. Cette fonction d√©j√† donn√©e divise le DataFrame en deux ensembles : un ensemble d'entra√Ænement et un ensemble de test.

##### 1.11.2 normalize_data(x_train, x_test)

La mise √† l'√©chelle des donn√©es est cruciale lors de l'utilisation de mod√®les qui sont sensibles √† la magnitude des entr√©es. Cette fonction normalise les caract√©ristiques d'entra√Ænement et de test. Pour ce faire, vous utiliserez la classe [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) de Scikit-Learn. L'objectif est de centrer les donn√©es autour de 0 et de les mettre √† l'√©chelle pour avoir une variance unitaire. Les m√©thodes [fit_transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform) et [transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform) de la classe StandardScaler vous seront utiles respectivement pour l'ensemble d'entra√Ænement et l'ensemble de test. Cette fonction retournera les ensembles d'entra√Ænement et de test normalis√©s.

##### 1.11.3 train_model(x_train, y_train)

Apr√®s la pr√©paration des donn√©es, il est temps d'entra√Æner le mod√®le. Cette fonction prend les caract√©ristiques et les labels d'entra√Ænement et renvoie un mod√®le entra√Æn√©. Pour ce faire, vous utiliserez la classe [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) de Scikit-Learn. Vous pouvez utiliser les param√®tres par d√©faut (n_neighbors=5). La m√©thode [fit](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit) de la classe KNeighborsClassifier vous permettra d'entra√Æner le mod√®le qui sera retourn√© par la fonction.

##### 1.11.4 evaluate_model(model, x_test, y_test)

Une fois le mod√®le form√©, l'√©tape suivante est de le tester sur les donn√©es que le mod√®le n'a jamais vues. Cette fonction √©value les performances du mod√®le sur l'ensemble de test. Pour ce faire, vous utiliserez la m√©thode [predict](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict) de la classe KNeighborsClassifier pour pr√©dire les labels de l'ensemble de test et la fonction [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) de pour calculer la pr√©cision du mod√®le, qui sera retourn√©e par la fonction.

##### 1.11.5 predict_legendary(df)

Cette fonction agit comme coordinateur, orchestrant l'ex√©cution de toutes les fonctions ci-dessus. Elle est √©galement responsable de l'impression de la pr√©cision du mod√®le. Voici les √©tapes √† suivre pour compl√©ter cette fonction :
- Divisez le DataFrame en ensembles d'entra√Ænement et de test en appelant la fonction `split_data(df)`.
- Normalisez les ensembles d'entra√Ænement et de test en appelant la fonction `normalize_data(x_train, x_test)`.
- Utilisez les ensembles d'entra√Ænement normalis√©s pour entra√Æner le mod√®le en appelant la fonction `train_model(x_train, y_train)`.
- Utilisez le mod√®le entra√Æn√© pour √©valuer les performances sur l'ensemble de test en appelant la fonction `evaluate_model(model, x_test, y_test)`.
- Affichez le nombre de donn√©es d'entra√Ænement et de test.
- Affichez la pr√©cision du mod√®le.

**Afficahge attendu:**
![Q1.11](/assets/Q1.11.png)

**Insight** : La pr√©cision du mod√®le vous donne un aper√ßu de la fiabilit√© des pr√©dictions. Plus la pr√©cision est √©lev√©e, plus vous pouvez √™tre s√ªr que le mod√®le pr√©dit correctement la l√©gendarit√© d'un Pok√©mon en fonction de ses statistiques.


## Partie 2: L'Ar√®ne des Pok√©mons

Dans cette deuxi√®me section du TP, nous changeons de cap et plongeons dans le monde passionant de la programmation orient√©e objet. Vous aurez la t√¢che de cr√©er une simulation de combat entre Pok√©mon, tour par tour, en utilisant la puissante de la POO. Vous allez cr√©er plusieurs classes, notamment une classe abstraite `Pokemon` pour repr√©senter un Pok√©mon avec toutes ses caract√©ristiques, d'autres classes abstraites pour repr√©senter les diff√©rents types de Pok√©mon, et enfin des classes concr√®tes pour repr√©senter les Pok√©mon eux-m√™mes. Vous allez √©galement cr√©er une classe `PokemonBattle` pour orchestrer les duels.

Ce segment a donc pour but de vous familiariser avec les concepts de base de la POO en Python en mettant l'accent sur l'encapsulation, l'h√©ritage, et le polymorphisme.

Pr√©parez-vous √† entrer dans l'ar√®ne! üèüÔ∏è


## Annexe: Guide et normes de codage
- [Le guide maison](https://github.com/INF1007-Gabarits/Guide-codage-python) de normes suppl√©mentaires √† respecter
- [Le plugin Pycharm Pylint](https://plugins.jetbrains.com/plugin/11084-pylint) qui analyse votre code et indique certaines erreurs. Vous avertis aussi si vous ne respectez pas certaines de normes de PEP8.
- [Quelques indications en fran√ßais sur PEP8](https://openclassrooms.com/fr/courses/4425111-perfectionnez-vous-en-python/4464230-assimilez-les-bonnes-pratiques-de-la-pep-8)
- [La documentation PEP8 Officielle](https://www.python.org/dev/peps/pep-0008/)
